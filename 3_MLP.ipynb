{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LAB4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "dyqnfEOKnNkM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lab 4: Evaluation and Multi-Layer Perceptron "
      ]
    },
    {
      "metadata": {
        "id": "Rrwb2Hy6CKR8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Group Members: Christina DeSantiago, Estefy Fiallos, Kaiying Li, Tianyu Li"
      ]
    },
    {
      "metadata": {
        "id": "By0xOegRoe2a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this lab, you will compare the performance of multi-layer perceptrons programmed in scikit-learn and via your own implementation. \n",
        "\n",
        "Select a dataset identically to the way you selected for lab one or lab three (table data or image data). You are not required to use the same dataset that you used in the past, but you are encouraged. You must identify a classification task from the dataset that contains three or more classes to predict. That is, it cannot be a binary classification; it must be multi-class prediction. "
      ]
    },
    {
      "metadata": {
        "id": "LNIeBYSynQxX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ]
    },
    {
      "metadata": {
        "id": "DEQ8eWevnl2D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**[5 points] (mostly the same processes as from previous lab) Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). Detail exactly what the task is and what parties would be interested in the results. How well would your prediction algorithm need to perform to be considered useful by interested parties?**"
      ]
    },
    {
      "metadata": {
        "id": "VcqM1_tjGrj5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For this lab, we chose the same dataset as lab one: Ames Housing Data. Our task is to classify houses into one of three price ranges based on the various attributes of the property (# of bedrooms, square footage, year built, etc). Our price ranges are labeled as 0, 1, 2 to represent a low, medium, and high price.\n",
        "\n",
        "For the buyers, it will be convenient for them to narrow down the house choices within their budget range by selecting the number of bedrooms and bathrooms, garage types and other features when they are in the house market.\n",
        "\n",
        "On the other hand, for sellers such as real estate or construction company, it is crucial to understand which type of houses or floor plan are more desirable in the market. Predicting the sales prices of different type of houses not only helps them optimize their asset acquisition or construction plan, it also leads to quicker asset turn over and smooth sales process. Ultimately a greater profit is achieved. It would also be important for a real estate company to predict the price range of a house specifically for meeting quotas. Sales representatives often have quotas to meet each business quarter for their sales. Understanding the predicted price range of a property will allow a sales rep to push more towards certain kinds of properties in order to meet these quotas. Sellers can use our algorithm as a guide to price their properties. \n",
        "\n",
        "There are two possible types of misclassification in our dataset - one is between adjacent categories (low, medium and medium, high) and the other is between low and high sales price categories. Our algorithm would not be useful for realtors if there are any misclassifications between lowest and highest priced houses. This would not only show that the algorithm does not work but could also lead to a significant loss of revenue for the seller. There is a little more room for error for houses that might be on the borderline between price ranges. Zillow uses Zestimates to predict house prices. According to https://www.zillow.com/zestimate/, the Zestimate was within 20% of the transaction price for 87.6% of properties across the U.S. Using this number as a rough guideline, we can estimate that the algorithm would still be useful with about a 10% misclassification rate for houses that are on the borderline between price ranges.  "
      ]
    },
    {
      "metadata": {
        "id": "kHVWEFB3nrv8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**[10 points] (mostly the same processes as from lab one) Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification (include a description of any newly formed variables you created).**"
      ]
    },
    {
      "metadata": {
        "id": "eUXbjnRXeqbp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We used our same dataset from lab one with a subset of 8 attributes: Gr Liv Area = Above ground living area (continuous), SalePrice = Sales price in dollars (continuous), Year built (discrete), Full Bath = number of full bathrooms (discrete), Bedroom AbvGr = number of bedrooms above ground (discrete), Garage Type (nominal), Lot frontage (continuous), Lot Area (continuous).\n",
        "\n",
        "We changed the Garage Type variable to be one-hot encoded, creating 7 new dummy variables for our data set. We used the same method of imputing missing values in Lot Frontage based on Lot Area. We also transformed our SalePrice variable into a Price_Range variable. Instead of having a continuous response variable, we now have a categorical response with 3 different levels of pricing so we can use multi level classification. We used the distribution of SalePrice, which we investigated in lab one, to determine how to split the prices into ranges. A house with sale price less than 130,000 dollars is assigned to the lowest price range \"0\" and houses with sale price above 210,000 dollars are assigned to the highest price range \"2\". We also used MinMax Scaler to normalize our data.\n",
        "\n",
        "Our final data sets has are: X, with 14 predictors (7 dummy variables for Garage Type + 7 previously defined variables) and y, with 1 target variable.\n"
      ]
    },
    {
      "metadata": {
        "id": "YIpHXUn_JE_N",
        "colab_type": "code",
        "outputId": "61e72a62-600a-4bb7-ac88-2b9efd492289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "#import data set\n",
        "import pandas as pd\n",
        "df2=pd.read_csv(\"https://raw.githubusercontent.com/skytianyuli/MLPython/master/ames.csv\", sep=\",\")\n",
        "\n",
        "#make a subset of the dataset only with the variables we are interested in\n",
        "to_keep=['Lot.Frontage','Lot.Area','Year.Built', 'Gr.Liv.Area','Full.Bath', 'Bedroom.AbvGr','Garage.Type', 'SalePrice']\n",
        "sub = df2[to_keep].copy()\n",
        "\n",
        "sub.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2930 entries, 0 to 2929\n",
            "Data columns (total 8 columns):\n",
            "Lot.Frontage     2440 non-null float64\n",
            "Lot.Area         2930 non-null int64\n",
            "Year.Built       2930 non-null int64\n",
            "Gr.Liv.Area      2930 non-null int64\n",
            "Full.Bath        2930 non-null int64\n",
            "Bedroom.AbvGr    2930 non-null int64\n",
            "Garage.Type      2773 non-null object\n",
            "SalePrice        2930 non-null int64\n",
            "dtypes: float64(1), int64(6), object(1)\n",
            "memory usage: 183.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVQfGHa8MHz9",
        "colab_type": "code",
        "outputId": "24713c9e-9f77-4d86-abf3-c5c37177c3ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "#Change NA values in 'Garage Type' to No_Garage (since NA is described as no garage in data documentation)\n",
        "sub['Garage.Type'].fillna(value='No_Garage', inplace= True)\n",
        "sub.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2930 entries, 0 to 2929\n",
            "Data columns (total 8 columns):\n",
            "Lot.Frontage     2440 non-null float64\n",
            "Lot.Area         2930 non-null int64\n",
            "Year.Built       2930 non-null int64\n",
            "Gr.Liv.Area      2930 non-null int64\n",
            "Full.Bath        2930 non-null int64\n",
            "Bedroom.AbvGr    2930 non-null int64\n",
            "Garage.Type      2930 non-null object\n",
            "SalePrice        2930 non-null int64\n",
            "dtypes: float64(1), int64(6), object(1)\n",
            "memory usage: 183.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yQ4rKDUhMK1t",
        "colab_type": "code",
        "outputId": "db55c2d2-1869-4d19-8de6-94fa85d63e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "#one hot encoding for the Garage Type variable\n",
        "tmp = pd.get_dummies(sub['Garage.Type'])\n",
        "result = pd.concat([sub, tmp],axis=1, join_axes=[sub.index])\n",
        "del result['Garage.Type'] #delete since we have the dummy variables now\n",
        "result.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lot.Frontage</th>\n",
              "      <th>Lot.Area</th>\n",
              "      <th>Year.Built</th>\n",
              "      <th>Gr.Liv.Area</th>\n",
              "      <th>Full.Bath</th>\n",
              "      <th>Bedroom.AbvGr</th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>2Types</th>\n",
              "      <th>Attchd</th>\n",
              "      <th>Basment</th>\n",
              "      <th>BuiltIn</th>\n",
              "      <th>CarPort</th>\n",
              "      <th>Detchd</th>\n",
              "      <th>No_Garage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>141.0</td>\n",
              "      <td>31770</td>\n",
              "      <td>1960</td>\n",
              "      <td>1656</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>215000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>80.0</td>\n",
              "      <td>11622</td>\n",
              "      <td>1961</td>\n",
              "      <td>896</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>105000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>81.0</td>\n",
              "      <td>14267</td>\n",
              "      <td>1958</td>\n",
              "      <td>1329</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>172000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>93.0</td>\n",
              "      <td>11160</td>\n",
              "      <td>1968</td>\n",
              "      <td>2110</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>244000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>74.0</td>\n",
              "      <td>13830</td>\n",
              "      <td>1997</td>\n",
              "      <td>1629</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>189900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Lot.Frontage  Lot.Area  Year.Built  Gr.Liv.Area  Full.Bath  Bedroom.AbvGr  \\\n",
              "0         141.0     31770        1960         1656          1              3   \n",
              "1          80.0     11622        1961          896          1              2   \n",
              "2          81.0     14267        1958         1329          1              3   \n",
              "3          93.0     11160        1968         2110          2              3   \n",
              "4          74.0     13830        1997         1629          2              3   \n",
              "\n",
              "   SalePrice  2Types  Attchd  Basment  BuiltIn  CarPort  Detchd  No_Garage  \n",
              "0     215000       0       1        0        0        0       0          0  \n",
              "1     105000       0       1        0        0        0       0          0  \n",
              "2     172000       0       1        0        0        0       0          0  \n",
              "3     244000       0       1        0        0        0       0          0  \n",
              "4     189900       0       1        0        0        0       0          0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "7y9xwhXkMRe9",
        "colab_type": "code",
        "outputId": "d92ba7d2-3edd-42b7-f0a5-9212ba7f5562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "#Imputation of Lot Frontage\n",
        "#Breaking up 'Lot Area' into intervals\n",
        "result['Lot_Area_Ranges']= pd.cut(result['Lot.Area'], [0, 10000, 20000, 30000, 250000])\n",
        "\n",
        "result_grouped = result.groupby(by=['Lot_Area_Ranges'])\n",
        "\n",
        "#Fill missing values with mean within 'Lot Area' intervals\n",
        "func = lambda grp: grp.fillna(grp.mean())\n",
        "result_imputed= result_grouped.transform(func)\n",
        "\n",
        "# fill any deleted columns\n",
        "col_deleted = list( set(result.columns) - set(result_imputed.columns)) # in case the mean operation deleted columns\n",
        "result_imputed[col_deleted] = result[col_deleted]\n",
        "\n",
        "result_imputed.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2930 entries, 0 to 2929\n",
            "Data columns (total 15 columns):\n",
            "Lot.Frontage       2930 non-null float64\n",
            "Lot.Area           2930 non-null int64\n",
            "Year.Built         2930 non-null int64\n",
            "Gr.Liv.Area        2930 non-null int64\n",
            "Full.Bath          2930 non-null int64\n",
            "Bedroom.AbvGr      2930 non-null int64\n",
            "SalePrice          2930 non-null int64\n",
            "2Types             2930 non-null uint8\n",
            "Attchd             2930 non-null uint8\n",
            "Basment            2930 non-null uint8\n",
            "BuiltIn            2930 non-null uint8\n",
            "CarPort            2930 non-null uint8\n",
            "Detchd             2930 non-null uint8\n",
            "No_Garage          2930 non-null uint8\n",
            "Lot_Area_Ranges    2930 non-null category\n",
            "dtypes: category(1), float64(1), int64(6), uint8(7)\n",
            "memory usage: 183.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v3NsU_hlMk3h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#get rid of the \"Lot Area Range\" variable because we don't need it in prediction model\n",
        "result=result_imputed.copy()\n",
        "del result['Lot_Area_Ranges']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s74ky1vpNChQ",
        "colab_type": "code",
        "outputId": "a58d7023-e8eb-4a2a-81e2-72f10bd7f457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "#Break Sales price into 3 classes for prediction\n",
        "result['Price_Range']=pd.cut(result[\"SalePrice\"], [0,130000,210000,800000],labels=[0,1,2])\n",
        "#0=low, 1=mid, 2= high\n",
        "result.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2930 entries, 0 to 2929\n",
            "Data columns (total 15 columns):\n",
            "Lot.Frontage     2930 non-null float64\n",
            "Lot.Area         2930 non-null int64\n",
            "Year.Built       2930 non-null int64\n",
            "Gr.Liv.Area      2930 non-null int64\n",
            "Full.Bath        2930 non-null int64\n",
            "Bedroom.AbvGr    2930 non-null int64\n",
            "SalePrice        2930 non-null int64\n",
            "2Types           2930 non-null uint8\n",
            "Attchd           2930 non-null uint8\n",
            "Basment          2930 non-null uint8\n",
            "BuiltIn          2930 non-null uint8\n",
            "CarPort          2930 non-null uint8\n",
            "Detchd           2930 non-null uint8\n",
            "No_Garage        2930 non-null uint8\n",
            "Price_Range      2930 non-null category\n",
            "dtypes: category(1), float64(1), int64(6), uint8(7)\n",
            "memory usage: 183.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mwE_Il_ROBWy",
        "colab_type": "code",
        "outputId": "0b5e93cd-6838-4046-a73c-e7978f022fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "cell_type": "code",
      "source": [
        "#visualize Price Range with bar chart\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,6))\n",
        "result['Price_Range'].value_counts().plot(kind='bar')\n",
        "plt.title('Distribution of Price Range')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,1,'Distribution of Price Range')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAFwCAYAAACLs24kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMAAIgsAAMAAIgsAAMAAIgsAAMCA/w9686v2t19yzQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9c0b67fc18>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gxuuhpmesFi3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df=result.copy()\n",
        "del df['SalePrice']\n",
        "# we want to predict the X and y data as follows:\n",
        "if 'Price_Range' in df:\n",
        "    y = df['Price_Range'].values # get the labels we want\n",
        "    del df['Price_Range'] # get rid of the class label\n",
        "    X = df.values # use everything else to predict!\n",
        "\n",
        "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
        "    #    have converted them into simple matrices to use with scikit learn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fa7r-HJMsJ2M",
        "colab_type": "code",
        "outputId": "2244c9e6-2989-4547-8584-333c40b85bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "#Normalize data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(copy=False)\n",
        "scaler.fit(X)\n",
        "scaler.transform(X)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4109589 , 0.14241978, 0.63768116, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.20205479, 0.04824604, 0.64492754, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.20547945, 0.06060904, 0.62318841, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.14041096, 0.04272593, 0.86956522, ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.19178082, 0.0407114 , 0.73913043, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.18150685, 0.03892122, 0.87681159, ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "EMS8W1FinZZ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "NV5PHwEQnwGq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**[15 points] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s generalization performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why does the metric evaluate performance in terms of the business case you argued for. Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.**"
      ]
    },
    {
      "metadata": {
        "id": "9Qtrlz01NigN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will use a cost matrix as our evaluation method because we want to consider how different types of misclassifications will affect business from a seller's standpoint.\n",
        "\n",
        "If we classify a house as lower priced than it actually is, sellers would lose revenue when selling the house. If we classify a house as higher priced than it is, there would be less demand from buyers because the sales price is out of budget. This would ultimately would lead to loss of revenue for the seller because it would take longer to sell the house. This uses up the seller's time and resources while this time could have been spent selling an additional property. \n",
        "\n",
        "We chose to use different weights for the cost because misclassification between the lowest and highest price ranges would be worse than misclassifying houses that might be in the bordeline between price ranges. To choose the costs, we calculated the difference between median sales price for each pair of price range categories to have an estimate of how much the misclassification would cost the seller. Then, we set the misclassification between lowest and highest price ranges (0 and 2) to be 100 and normalized the other price differences to this. The resulting cost matrix is depicted below. \n"
      ]
    },
    {
      "metadata": {
        "id": "VehT1lsqMBvN",
        "colab_type": "code",
        "outputId": "77830b95-11fc-4195-9277-98d0cf8e5c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#determine values to use in cost matrix\n",
        "df2 = result.groupby(['Price_Range']).median()\n",
        "\n",
        "diff01 = df2.SalePrice[1] - df2.SalePrice[0] \n",
        "\n",
        "diff02 = df2.SalePrice[2] - df2.SalePrice[0]\n",
        "\n",
        "diff12 = df2.SalePrice[2] - df2.SalePrice[1]\n",
        "\n",
        "print(diff01, diff12, diff02)\n",
        "\n",
        "C02 = 100 #Setting the difference between highest and lowest price (diff02) to be 100\n",
        "C01 = diff01*100/diff02\n",
        "C12 = diff12*100/diff02\n",
        "\n",
        "print(C01, C12, C02)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48500.0 100364.5 148864.5\n",
            "32.579963658226106 67.4200363417739 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6BtXadaxMD46",
        "colab_type": "code",
        "outputId": "26512cc0-ca87-4b39-ed50-ce57a7e21e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#creating custom cost matrix\n",
        "import numpy as np\n",
        "cost_mat = np.matrix([[0,33,100],\n",
        "            [33,0,67],\n",
        "            [100,67,0]])\n",
        "print(cost_mat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0  33 100]\n",
            " [ 33   0  67]\n",
            " [100  67   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2qAHlmC6X0uL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The cost matrix above is how we will evaluate the performance of our model in conjunction with the confusion matrix.  "
      ]
    },
    {
      "metadata": {
        "id": "IuDEIj4Lnz0W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**[15 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time. Convince the reader that your cross validation method is a realistic mirroring of how an algorithm would be used in practice.** \n",
        "\n",
        "**Important: You should use your chosen evaluation criteria and chosen method for dividing train/test data throughout the report. For example, arguing that f-score is the best evaluation method, but then using accuracy in a grid search will be regarded as a conceptual error and graded accordingly.**"
      ]
    },
    {
      "metadata": {
        "id": "pTz1Z3v1VsgC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will use Stratified k fold cross validation for our data set. Stratified k fold aims to create folds that are representative of all classes in the data. Since we have slight class imbalance in our data set, (50% - class 1,  25% - class 0, 25% -  class 2), it is best to use stratified k fold to ensure all training folds contain accurate representation of each class. Also, statified k fold works well on small/medium data sets. With only 2930 observations in our set, it is appropriate to use stratified k fold in this case.\n",
        "\n",
        "We will also further split the training set to attain a validation data set to use for hyperparameter tuning (shown under \"Tuning parameters\")"
      ]
    },
    {
      "metadata": {
        "id": "BtCmc5P_Re0E",
        "colab_type": "code",
        "outputId": "0ed039a4-5e26-4c83-ee09-75a1ea921f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "skf = StratifiedKFold(n_splits=10,random_state=1)\n",
        "skf.get_n_splits(X, y)\n",
        "\n",
        "print(skf)  \n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1EQqQRNntPT2",
        "colab_type": "code",
        "outputId": "4ddcda94-4279-4e81-f44c-29b6ff86bd5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2639, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "TZ1UU1qMtSad",
        "colab_type": "code",
        "outputId": "ee0cf8b1-8f32-4a7a-c998-f7b2fd30e57b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(291, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "Eq1Bz9y4nc0E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ]
    },
    {
      "metadata": {
        "id": "vgaJmieRn51L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All modeling code must be written using only the instructor's template code. Do NOT copy this implementation form anywhere online. Not fully implementing the back propagation algorithm will result in a zero for the entire assignment."
      ]
    },
    {
      "metadata": {
        "id": "UKvA2-TZoCM1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**[20 points] Create a custom implementation of the multi-layer perceptron. Start with the implementation given to you in the course. Update the MLP class to:\n",
        "When instantiated, use a selectable phi function for the initial layer: either sigmoid or linear \n",
        "Use a selectable cost function when instantiated: either quadratic or cross entropy\n",
        "Add support for any number of hidden layers (user customizable).**"
      ]
    },
    {
      "metadata": {
        "id": "afCgWpcab-uA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "import pandas as pd\n",
        "import sys\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "#phif can be \"sigmoid\" or \"linear\"\n",
        "#costf can be \"q\" for quadratic or \"c\" for cross entropy\n",
        "#specify number of hidden layers in n_layer\n",
        "\n",
        "class MultLayerPerceptronBase(object):\n",
        "    def __init__(self, n_hidden=30,\n",
        "                 C=0.0, epochs=500, eta=0.001, phif=\"sigmoid\", costf=\"q\",n_layer=2,random_state=None):\n",
        "        np.random.seed(random_state)\n",
        "        self.n_hidden = n_hidden\n",
        "        self.l2_C = C\n",
        "        self.epochs = epochs\n",
        "        self.eta = eta\n",
        "        self.phif = phif\n",
        "        self.costf = costf\n",
        "        self.n_layer = n_layer\n",
        "        \n",
        "    @staticmethod\n",
        "    def _encode_labels(y):\n",
        "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
        "        onehot = pd.get_dummies(y).values.T\n",
        "            \n",
        "        return onehot\n",
        "    \n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
        "        W=[]\n",
        "        W1_num_elems = (self.n_features_ + 1)*self.n_hidden\n",
        "        W1 = np.random.uniform(-1.0, 1.0,size=W1_num_elems)\n",
        "        W1 = W1.reshape(self.n_hidden, self.n_features_ + 1) # reshape to be W\n",
        "        W.append(W1)\n",
        "        \n",
        "        for i in range(1,self.n_layer-1):          \n",
        "          W_num_elems = (self.n_hidden + 1)*self.n_hidden\n",
        "          Wi = np.random.uniform(-1.0, 1.0,size=W_num_elems)\n",
        "          Wi = Wi.reshape(self.n_hidden, self.n_hidden + 1) # reshape to be W\n",
        "          W.append(Wi)          \n",
        "        \n",
        "        WOUT_num_elems = (self.n_hidden + 1)*self.n_output_\n",
        "        WOUT = np.random.uniform(-1.0, 1.0, size=WOUT_num_elems)\n",
        "        WOUT = WOUT.reshape(self.n_output_, self.n_hidden + 1)\n",
        "        W.append(WOUT)\n",
        "        return W\n",
        "    \n",
        "    #define custom phi function  \n",
        "    def _phi(self,z):\n",
        "        if self.phif == \"linear\":\n",
        "          return(z)\n",
        "        return expit(z)   #default is the sigmoid\n",
        "      \n",
        "    @staticmethod\n",
        "    def _sigmoid(z):\n",
        "        \"\"\"Use scipy.special.expit to avoid overflow\"\"\"\n",
        "        # 1.0 / (1.0 + np.exp(-z))\n",
        "        return expit(z)\n",
        "    \n",
        "    @staticmethod\n",
        "    def _add_bias_unit(X, how='column'):\n",
        "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
        "        if how == 'column':\n",
        "            ones = np.ones((X.shape[0], 1))\n",
        "            X_new = np.hstack((ones, X))\n",
        "        elif how == 'row':\n",
        "            ones = np.ones((1, X.shape[1]))\n",
        "            X_new = np.vstack((ones, X))\n",
        "        return X_new\n",
        "    \n",
        "    @staticmethod\n",
        "    def _L2_reg(lambda_, W):\n",
        "        \"\"\"Compute L2-regularization cost\"\"\"\n",
        "        # only compute for non-bias terms\n",
        "        s=[]\n",
        "        for i in range(0,len(W)):\n",
        "          s.append(np.mean(W[i][:, 1:] ** 2))\n",
        "          result= (lambda_/2.0) * np.sqrt(np.sum(s))\n",
        "        return result\n",
        "    \n",
        "    #define custom cost function. Default is the quadratic\n",
        "    def _cost(self,AOUT,Y_enc,W):\n",
        "        '''Get the objective function value'''\n",
        "        #quadratic\n",
        "        if self.costf == \"q\":\n",
        "          cost = np.mean((Y_enc-AOUT)**2)\n",
        "        #cross entropy\n",
        "        elif self.costf == \"c\":\n",
        "          cost = -np.mean(np.nan_to_num((Y_enc*np.log(AOUT)+(1-Y_enc)*np.log(1-AOUT))))\n",
        "        \n",
        "        L2_term = self._L2_reg(self.l2_C, W)\n",
        "        return cost + L2_term\n",
        "      \n",
        "      \n",
        "    \n",
        "    def _feedforward(self, X, W):\n",
        "        \"\"\"Compute feedforward step\n",
        "        \"\"\"\n",
        "        A=[]\n",
        "        Z=[]\n",
        "        A0 = self._add_bias_unit(X, how='column')\n",
        "        A0 = A0.T\n",
        "        A.append(A0)\n",
        "        Z0 = W[0] @ A0\n",
        "        Z.append(Z0)\n",
        "        \n",
        "        A1 = self._phi(Z0)   #customized phi function only for the first layer\n",
        "        A1 = self._add_bias_unit(A1, how='row')\n",
        "        Z1 = W[1] @ A1\n",
        "        A.append(A1)\n",
        "        Z.append(Z1)\n",
        "        \n",
        "        for i in range(2,self.n_layer):\n",
        "          Ai = self._sigmoid(Z[-1])          \n",
        "          Ai = self._add_bias_unit(Ai, how='row')\n",
        "          Zi = W[i] @ Ai\n",
        "          A.append(Ai)\n",
        "          Z.append(Zi)\n",
        "\n",
        "        AOUT = self._sigmoid(Z[-1])\n",
        "        A.append(AOUT)\n",
        "        return A, Z, AOUT\n",
        "    \n",
        "    def _get_gradient(self, A, Z, AOUT, Y_enc, W):\n",
        "        \"\"\" Compute gradient step using backpropagation.\n",
        "        \"\"\"\n",
        "        # vectorized backpropagation\n",
        "        V=[0]*self.n_layer\n",
        "        if self.costf == \"q\":\n",
        "          V[-1] = -2*(Y_enc-AOUT)*AOUT*(1-AOUT)  # last layer sensitivity\n",
        "        elif self.costf == \"c\":\n",
        "          V[-1] = (AOUT-Y_enc)\n",
        "        \n",
        "        #all other sensitivities\n",
        "        V[-2]=A[-2]*(1-A[-2])*(W[-1].T @ V[-1])\n",
        "        for i in range(self.n_layer-3,-1,-1):\n",
        "          V[i] = A[i+1]*(1-A[i+1])*(W[i+1].T @ V[i+1][1:,:])\n",
        "        \n",
        "        #first sensitivity is different for linear activation function\n",
        "        if self.phif == \"linear\":\n",
        "          if self.n_layer >2:\n",
        "            V[0]=(W[1].T @ V[1][1:,:])\n",
        "          else:\n",
        "            V[0]=(W[1].T @ V[1])\n",
        "          #if equals 2 then don't take off bias\n",
        "        \n",
        "        grads = [0]*len(V)\n",
        "        grads[0] = V[0][1:,:] @ A[0].T\n",
        "        for i in range(1,len(V)-1):\n",
        "          grads[i] = V[i][1:,:] @ A[i].T\n",
        "        grads[-1] = V[-1] @ A[-2].T\n",
        "\n",
        "        for k in range(0,self.n_layer):\n",
        "          grads[k][:, 1:] += W[k][:, 1:] * self.l2_C \n",
        "        \n",
        "        return grads\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict class labels\"\"\"\n",
        "        _, _, AOUT = self._feedforward(X, self.W)\n",
        "        y_pred = np.argmax(AOUT, axis=0)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EjqQeBhMcJKd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MLPMiniBatch(MultLayerPerceptronBase):\n",
        "    def __init__(self, alpha=0.0, decrease_const=0.0, shuffle=True, \n",
        "                 minibatches=1, **kwds):        \n",
        "        # need to add to the original initializer \n",
        "        self.alpha = alpha\n",
        "        self.decrease_const = decrease_const\n",
        "        self.shuffle = shuffle\n",
        "        self.minibatches = minibatches\n",
        "        # but keep other keywords\n",
        "        super().__init__(**kwds)\n",
        "        \n",
        "    \n",
        "    def fit(self, X, y, print_progress=False):\n",
        "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
        "        X_data, y_data = X.copy(), y.copy()\n",
        "        Y_enc = self._encode_labels(y)\n",
        "        \n",
        "        # init weights and setup matrices\n",
        "        self.n_features_ = X_data.shape[1]\n",
        "        self.n_output_ = Y_enc.shape[0]\n",
        "        self.W = self._initialize_weights()\n",
        "        \n",
        "        # initialize grad_w_\n",
        "        self.grad_w_ = np.zeros(shape=(self.epochs,self.n_layer))\n",
        "\n",
        "        delta_W_prev=[]\n",
        "        for j in range(0,self.n_layer):\n",
        "          delta_Wj_prev = np.zeros(self.W[j].shape)\n",
        "          delta_W_prev.append(delta_Wj_prev)\n",
        "       \n",
        "\n",
        "        self.cost_ = []\n",
        "        self.score_ = []\n",
        "        # get starting acc\n",
        "        self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
        "        for i in range(self.epochs):\n",
        "\n",
        "            # adaptive learning rate\n",
        "            self.eta /= (1 + self.decrease_const*i)\n",
        "\n",
        "            if print_progress>0 and (i+1)%print_progress==0:\n",
        "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
        "                sys.stderr.flush()\n",
        "\n",
        "            if self.shuffle:\n",
        "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
        "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
        "\n",
        "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
        "            mini_cost = []\n",
        "            for idx in mini:\n",
        "\n",
        "                # feedforward\n",
        "                A, Z, AOUT = self._feedforward(X_data[idx],\n",
        "                                         self.W)\n",
        "                \n",
        "                cost = self._cost(AOUT,Y_enc[:, idx],self.W)\n",
        "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
        "\n",
        "                # compute gradient via backpropagation\n",
        "                grads = self._get_gradient(A,Z,AOUT,\n",
        "                                          Y_enc=Y_enc[:, idx],\n",
        "                                          W=self.W)\n",
        "                \n",
        "                # get magnitude of gradients\n",
        "                for m in range(0,self.n_layer):\n",
        "                  self.grad_w_[i][m]=np.mean(np.abs(grads[m]))\n",
        "\n",
        "                # momentum calculations\n",
        "                delta_W=[]\n",
        "                for k in range(0,self.n_layer):\n",
        "                  delta_Wk = self.eta * grads[k]\n",
        "                  delta_W.append(delta_Wk)\n",
        "                  self.W[k] -= (delta_W[k] + (self.alpha * delta_W_prev[k]))\n",
        "                delta_W_prev = delta_W\n",
        "\n",
        "            self.cost_.append(mini_cost)\n",
        "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
        "            \n",
        "        return self\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ai4I97OcL4p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "params = dict(n_hidden=50, \n",
        "              C=0.1, # tradeoff L2 regularizer\n",
        "              epochs=200, # iterations\n",
        "              eta=0.001,  # learning rate\n",
        "              n_layer=3,\n",
        "              random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QNU5PfKab4Aw",
        "colab_type": "code",
        "outputId": "40d43a81-5494-4b30-edf1-0cba1bdd4cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "#testing if our classifier runs correctly\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "nn = MLPMiniBatch(**params, phif='linear')\n",
        "nn.fit(X_train, y_train, print_progress=50)\n",
        "yhat=nn.predict(X_test)\n",
        "\n",
        "confusion_matrix(y_test,yhat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 200/200"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[53, 21,  3],\n",
              "       [23, 60, 55],\n",
              "       [ 1,  9, 66]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "i3nyr3VUggy-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tuning parameters"
      ]
    },
    {
      "metadata": {
        "id": "GANKvr30oIWC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**[15 points] Tune the hyper-parameters of your MLP model (phi function, objective function, and number of layers). While tuning hyper-parameters, analyze the results using your chosen metric(s) of evaluation. Visualize the evaluation metric(s) versus the hyper-parameters. Conclude what combination of parameters are best.**"
      ]
    },
    {
      "metadata": {
        "id": "DpS-Fx1szGPK",
        "colab_type": "code",
        "outputId": "485cb9e1-dfeb-42a7-9704-b3dc25bbdbe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#using cv to compare performance of different cost and activation functions\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "\n",
        "#use stratified k fold to split into training and validation set\n",
        "skf = StratifiedKFold(n_splits=10, random_state=1)\n",
        "skf.get_n_splits(X_train, y_train)\n",
        "print(skf)  \n",
        "\n",
        "mod_1=MLPMiniBatch(costf=\"q\", phif=\"sigmoid\", n_layer=3)\n",
        "mod_2=MLPMiniBatch(costf=\"q\", phif=\"linear\", n_layer=3)\n",
        "mod_3=MLPMiniBatch(costf=\"c\", phif=\"sigmoid\", n_layer=3)\n",
        "mod_4=MLPMiniBatch(costf=\"c\", phif=\"linear\", n_layer=3)\n",
        "\n",
        "models = [mod_1, mod_2, mod_3, mod_4]\n",
        "score_mat=[]\n",
        "\n",
        "for train_index, test_index in skf.split(X_train, y_train):\n",
        "    X_trainnew, X_valid = X_train[train_index], X_train[test_index]\n",
        "    y_trainnew, y_valid = y_train[train_index], y_train[test_index]\n",
        "    #need to fit\n",
        "    score=[]\n",
        "    for i in range(0,4):\n",
        "      models[i].fit(X_trainnew,y_trainnew)\n",
        "    #need to predict\n",
        "      yhat_i=models[i].predict(X_valid)\n",
        "    #evaluate model  \n",
        "      score_i=confusion_matrix(y_valid,yhat_i)\n",
        "      cost_i=score_i * cost_mat\n",
        "      score.append(np.sum(cost_i))\n",
        "    #keep track of overall costs for all models per fold\n",
        "    score_mat.append(score)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StratifiedKFold(n_splits=10, random_state=1, shuffle=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hSdZj2fC710j",
        "colab_type": "code",
        "outputId": "24532575-6f82-4ce3-c4fa-f8a5a714f7fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(X_trainnew.shape)\n",
        "print(X_valid.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2376, 13)\n",
            "(263, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CoPbQuOs3S7R",
        "colab_type": "code",
        "outputId": "d2870597-2ab4-403d-fbd2-64e9741a33b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(score_mat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[34217, 31014, 33607, 33603], [30829, 35835, 36307, 31730], [33338, 33472, 33373, 30129], [30185, 35056, 31995, 35257], [34453, 34415, 32050, 30509], [30738, 33705, 31970, 34122], [36108, 31965, 36409, 35656], [31436, 33140, 33109, 32774], [30018, 31085, 30651, 35558], [31154, 32020, 34157, 34354]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "prYz9zbJw0oE",
        "colab_type": "code",
        "outputId": "4ab03ef8-2acf-4b3c-a14f-c53e907455e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "#re-format overall costs into a matrix\n",
        "scores=np.zeros(shape=(10,4))\n",
        "for k in range(0,10):\n",
        "  for m in range(0,4):\n",
        "    scores[k,m]=score_mat[k][m]\n",
        "print(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[34217. 31014. 33607. 33603.]\n",
            " [30829. 35835. 36307. 31730.]\n",
            " [33338. 33472. 33373. 30129.]\n",
            " [30185. 35056. 31995. 35257.]\n",
            " [34453. 34415. 32050. 30509.]\n",
            " [30738. 33705. 31970. 34122.]\n",
            " [36108. 31965. 36409. 35656.]\n",
            " [31436. 33140. 33109. 32774.]\n",
            " [30018. 31085. 30651. 35558.]\n",
            " [31154. 32020. 34157. 34354.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mzb5GmTy40XB",
        "colab_type": "code",
        "outputId": "28e462d3-1f4b-47a1-8be2-bbbc6e0497e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#compare mean cost per model\n",
        "np.mean(scores,0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([32247.6, 33170.7, 33362.8, 33369.2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "metadata": {
        "id": "U4_wwRuQ6RZw",
        "colab_type": "code",
        "outputId": "4ca6cb19-ee65-4af0-e2c2-c305f093a488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "#visualize difference in performance\n",
        "plt.boxplot(scores)\n",
        "plt.xticks([1, 2, 3, 4], ['q & sigmoid', 'q & linear', 'c & sigmoid','c & linear'])\n",
        "plt.title(\"Distribution of Cost vs. Parameters\")\n",
        "plt.ylabel(\"Overall Cost\")\n",
        "plt.xlabel(\"Models\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFnCAYAAACsMZCtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2872788f60>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "fjZkp74xgRGn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To begin tuning our parameters, we used stratified 10-fold cross validation and performed a grid search with all combinations of cost and activation functions used in the models. Within each fold, we used the confusion matrix and our chosen cost matrix to evaluate the performance of the models. The boxplot above shows similar performance for all the models. The lowest mean cost of ~32,000 was attained with the quadratic cost function and sigmoid activation function.  \n",
        "\n",
        "As stated earlier, we can estimate that the algorithm would still be useful with about a 10% misclassification rate for houses that are on the borderline between price ranges. With 263 observations in our validation set, this means we could incorrectly classify at most 26 properties. We do not want any these errors to occur in the upper right or lower left corners of the confusion matrix. If all errors occured at a position between the lowest and middle price range, overall cost would be (26 x 33 = 858). If all errors occured at a position between the middle and highest price range, overall cost would be (26 x 67 = 1,742). When evaluating our model on the validation dataset, any overall cost below ~1700 would be acceptable. However, we see that all models perform with costs between 30,000 and 37,000. "
      ]
    },
    {
      "metadata": {
        "id": "oRJ5LouwXyP2",
        "colab_type": "code",
        "outputId": "7332e0ec-0a45-4c43-d3ec-f28678c7c23d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#we use StratifiedKFold cross validation to tune the parameter n_layer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "skf = StratifiedKFold(n_splits=10, random_state=1)\n",
        "skf.get_n_splits(X_train, y_train)\n",
        "layer=range(2,11,1)\n",
        "print(skf) \n",
        "\n",
        "models=[]\n",
        "for i in range(len(layer)):\n",
        "  mod = MLPMiniBatch(phif=\"sigmoid\",costf=\"q\", n_layer=layer[i])\n",
        "  models.append(mod)\n",
        "\n",
        "\n",
        "score_mat=[]\n",
        "for train_index, test_index in skf.split(X_train, y_train):\n",
        "    X_trainnew, X_valid = X_train[train_index], X_train[test_index]\n",
        "    y_trainnew, y_valid = y_train[train_index], y_train[test_index]\n",
        "    #need to fit\n",
        "    score=[]\n",
        "    for i in range(0,9):\n",
        "      \n",
        "      models[i].fit(X_trainnew,y_trainnew)\n",
        "\n",
        "    #need to predict\n",
        "      yhat_i=models[i].predict(X_valid)\n",
        "    #evaluate model  \n",
        "      score_i=confusion_matrix(y_valid, yhat_i)\n",
        "      cost_i=score_i * cost_mat\n",
        "      score.append(np.sum(cost_i))\n",
        "    #keep track of overall costs per # of layers\n",
        "    score_mat.append(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StratifiedKFold(n_splits=10, random_state=1, shuffle=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XGQmBQcfcrip",
        "colab_type": "code",
        "outputId": "0cd09002-c007-4b73-a1a5-0e5effb11af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "#re-format overall costs into a matrix\n",
        "scores_layer=np.zeros(shape=(10,9))\n",
        "for k in range(0,10):\n",
        "  for m in range(0,9):\n",
        "    scores_layer[k,m]=score_mat[k][m]\n",
        "print(scores_layer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[35071. 34183. 34353. 30742. 31111. 30608. 33423. 26500. 29305.]\n",
            " [37030. 36674. 31463. 31530. 37077. 37345. 37823. 29734. 26400.]\n",
            " [31481. 33635. 33472. 31069. 33674. 34541. 29700. 34222. 26400.]\n",
            " [35849. 30217. 35733. 30647. 35800. 32192. 38929. 27720. 28809.]\n",
            " [30925. 30383. 34388. 30715. 31584. 35392. 36373. 29640. 33340.]\n",
            " [34961. 33873. 34106. 34239. 34872. 34937. 35498. 36450. 31581.]\n",
            " [30871. 36541. 36677. 37012. 32102. 37244. 28281. 29545. 28017.]\n",
            " [30748. 31404. 31733. 31732. 34042. 33995. 32077. 29898. 29766.]\n",
            " [35446. 34688. 34924. 34993. 35392. 32353. 29575. 34304. 26300.]\n",
            " [35013. 31420. 31384. 31952. 35093. 34747. 35447. 26300. 26300.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PhoRURcdcyRq",
        "colab_type": "code",
        "outputId": "4e814bbc-6f08-44f1-fe42-ae1b8a6cd107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "np.mean(scores_layer,0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([33739.5, 33301.8, 33823.3, 32463.1, 34074.7, 34335.4, 33712.6,\n",
              "       30431.3, 28621.8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "kAHVFGB4cJDn",
        "colab_type": "code",
        "outputId": "63438df7-c091-4170-ac15-fde260912939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "#visualize performance for different number of layers\n",
        "plt.boxplot(scores_layer)\n",
        "plt.xticks(range(1,10), range(2,11))\n",
        "plt.title(\"Distribution of Cost vs. # of Layers\")\n",
        "plt.ylabel(\"Overall Cost\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFZCAYAAACSQfZwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nk/j/ALkO3jdfkTqlAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9c077cc0f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "x0L5sp2YoNW1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We repeated the same process to tune the number of layers to use in our model with quadratic cost function and sigmoid activation function. We believe that using 5 layers is the best choice because it has the lowest mean overall cost for layers 1-8. The mean overall cost was 32,463 which was third lowest cost for all models tested. Although the overall cost was the lowest for 10 layers, we thought that using this many layers might lead to overtraining the model and could also cause issues with either vanishing or exploding gradients. "
      ]
    },
    {
      "metadata": {
        "id": "w2OwBekkjsxf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After tuning our parameters, we believe that the \"best\" combination is to use a neural network with sigmoid activation function, quadratic cost function, and 5 total layers."
      ]
    },
    {
      "metadata": {
        "id": "IxE3qMgqORc6",
        "colab_type": "code",
        "outputId": "bd1b3bec-25b3-47ab-a3d9-3d808aa409d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "#Evaluate final model on test set\n",
        "\n",
        "nn = MLPMiniBatch(phif=\"sigmoid\",costf=\"q\", n_layer=5)\n",
        "nn.fit(X_train, y_train, print_progress=50)\n",
        "yhat=nn.predict(X_test)\n",
        "\n",
        "score=confusion_matrix(y_test,yhat)\n",
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 500/500"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[41, 36,  0],\n",
              "       [15, 83, 40],\n",
              "       [ 0, 15, 61]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "GY3k6j_MPpKb",
        "colab_type": "code",
        "outputId": "a204f5fc-dbe7-4a05-94e9-d2d9b2c70291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "cost=score * cost_mat\n",
        "np.sum(cost)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "YTeVQixJRADd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our final model was successful in not misclassifying any properties between lowest and highest price range. The testing data contains 291 observations. If allowing for 10% misclassification rate, we could at most misclassify 29 houses. The highest acceptable cost would be (29 x 67) 1,943. The cost of misclassification for the final model was 37,915, so, we would not recommend this model for deployment since it's not likely to be useful for realtors. "
      ]
    },
    {
      "metadata": {
        "id": "DWM5zdMdoLli",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**[10 points] Visualize the magnitude of the gradients in each layer of the neural network versus the training iteration. Do the gradients stay consistent in each layer?**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "jdKKOm6cS34w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#save magnitude of gradients\n",
        "grad=nn.grad_w_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sqeq3MGvTDhg",
        "colab_type": "code",
        "outputId": "2314240f-118f-4bd6-f4f0-7c79658ae7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "cell_type": "code",
      "source": [
        "#visualize magnitude of gradients\n",
        "ax = plt.subplot(1,1,1)\n",
        "for i in range(len(grad[0,:])):\n",
        "  plt.plot(abs(grad[10:,i]), label=(\"w\",i+1))\n",
        "plt.legend()\n",
        "plt.ylabel('Average gradient magnitude')\n",
        "plt.xlabel('Iteration')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFYCAYAAAB+s6Q9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nESpoK4qiKMoUoYK2oiiKokwR/x8KFfVXsdK+PgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7dd06e4a20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "w43hFWI9omRg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "No, the gradients do not stay consistent in each layer. We visualized the gradients for 5 layers, and we see that they are all have different magnitudes. The gradients begin to stabilize around 200 iterations. It appears that after 300 iterations, the lower weights (W1 and W2) are being updated by the higher order weights."
      ]
    },
    {
      "metadata": {
        "id": "7Xp0hSctngnJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exceptional Work"
      ]
    },
    {
      "metadata": {
        "id": "rlp9pwUWoPWE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You have free reign to provide additional analyses.\n",
        "One idea (required for 7000 level students):  Implement two more phi functions: ReLU and SiLU (also called Swish). Compare their performance to the linear and sigmoid phi functions. "
      ]
    },
    {
      "metadata": {
        "id": "sjH8JNNkt4bY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##adapted for using relu and silu\n",
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "import pandas as pd\n",
        "import sys\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "#phif can be \"sigmoid\" , \"linear\", \"relu\", or \"silu\"\n",
        "#costf can be \"q\" for quadratic or \"c\" for cross entropy\n",
        "class MultLayerPerceptronBase2(object):\n",
        "    def __init__(self, n_hidden=30,\n",
        "                 C=0.0, epochs=500, eta=0.001, phif=\"sigmoid\", costf=\"q\",n_layer=2,random_state=None):\n",
        "        np.random.seed(random_state)\n",
        "        self.n_hidden = n_hidden\n",
        "        self.l2_C = C\n",
        "        self.epochs = epochs\n",
        "        self.eta = eta\n",
        "        self.phif = phif\n",
        "        self.costf = costf\n",
        "        self.n_layer = n_layer\n",
        "        \n",
        "    @staticmethod\n",
        "    def _encode_labels(y):\n",
        "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
        "        onehot = pd.get_dummies(y).values.T\n",
        "            \n",
        "        return onehot\n",
        "    \n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
        "        W=[]\n",
        "        if self.phif != (\"relu\" or \"silu\"):\n",
        "          W1_num_elems = (self.n_features_ + 1)*self.n_hidden\n",
        "          W1 = np.random.uniform(-1.0, 1.0,size=W1_num_elems)\n",
        "          W1 = W1.reshape(self.n_hidden, self.n_features_ + 1) # reshape to be W\n",
        "          W.append(W1)\n",
        "        \n",
        "          for i in range(1,self.n_layer-1):          \n",
        "            W_num_elems = (self.n_hidden + 1)*self.n_hidden\n",
        "            Wi = np.random.uniform(-1.0, 1.0,size=W_num_elems)\n",
        "            Wi = Wi.reshape(self.n_hidden, self.n_hidden + 1) # reshape to be W\n",
        "            W.append(Wi)          \n",
        "        \n",
        "          WOUT_num_elems = (self.n_hidden + 1)*self.n_output_\n",
        "          WOUT = np.random.uniform(-1.0, 1.0, size=WOUT_num_elems)\n",
        "          WOUT = WOUT.reshape(self.n_output_, self.n_hidden + 1)\n",
        "          W.append(WOUT)\n",
        "        #initialize different weights for relu and silu        \n",
        "        else:\n",
        "          init_bound = np.sqrt(6. / (self.n_hidden + self.n_features_ + 1))\n",
        "          W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_ + 1))\n",
        "          W1[:,:1] = 0\n",
        "          W.append(W1)\n",
        "          \n",
        "          for i in range(1,self.n_layer-1):          \n",
        "            init_bound = np.sqrt(6. / (self.n_hidden + self.n_hidden +1))\n",
        "            Wi = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_hidden+ 1))\n",
        "            Wi[:,:1] = 0\n",
        "            W.append(Wi)\n",
        "          \n",
        "          init_bound = np.sqrt(0.5 / (self.n_output_ + self.n_hidden + 1))\n",
        "          WOUT = np.random.uniform(-init_bound, init_bound, (self.n_output_, self.n_hidden +1))\n",
        "          WOUT[:,:1] = 0\n",
        "          W.append(WOUT)\n",
        "          \n",
        "        return W\n",
        "    \n",
        "    #define custom phi function  \n",
        "    def _phi(self,z):\n",
        "        if self.phif == \"linear\":\n",
        "          return(z)\n",
        "        elif self.phif == \"relu\":\n",
        "          return np.maximum(0,z.copy())\n",
        "        elif self.phif == \"silu\":\n",
        "          return (z * expit(z))\n",
        "        return expit(z)   #default is the sigmoid\n",
        "      \n",
        "    @staticmethod\n",
        "    def _sigmoid(z):\n",
        "        \"\"\"Use scipy.special.expit to avoid overflow\"\"\"\n",
        "        # 1.0 / (1.0 + np.ex\n",
        "        #p(-z))\n",
        "        return expit(z)\n",
        "    \n",
        "    @staticmethod\n",
        "    def _add_bias_unit(X, how='column'):\n",
        "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
        "        if how == 'column':\n",
        "            ones = np.ones((X.shape[0], 1))\n",
        "            X_new = np.hstack((ones, X))\n",
        "        elif how == 'row':\n",
        "            ones = np.ones((1, X.shape[1]))\n",
        "            X_new = np.vstack((ones, X))\n",
        "        return X_new\n",
        "    \n",
        "    @staticmethod\n",
        "    def _L2_reg(lambda_, W):\n",
        "        \"\"\"Compute L2-regularization cost\"\"\"\n",
        "        # only compute for non-bias terms\n",
        "        s=[]\n",
        "        for i in range(0,len(W)):\n",
        "          s.append(np.mean(W[i][:, 1:] ** 2))\n",
        "          result= (lambda_/2.0) * np.sqrt(np.sum(s))\n",
        "        return result\n",
        "    \n",
        "    #define custom cost function. Default is the quadratic\n",
        "    def _cost(self,AOUT,Y_enc,W):\n",
        "        '''Get the objective function value'''\n",
        "        #quadratic\n",
        "        if self.costf == \"q\":\n",
        "          cost = np.mean((Y_enc-AOUT)**2)\n",
        "        #cross entropy\n",
        "        elif self.costf == \"c\":\n",
        "          cost = -np.mean(np.nan_to_num((Y_enc*np.log(AOUT)+(1-Y_enc)*np.log(1-AOUT))))\n",
        "        \n",
        "        L2_term = self._L2_reg(self.l2_C, W)\n",
        "        return cost + L2_term\n",
        "      \n",
        "      \n",
        "    \n",
        "    def _feedforward(self, X, W):\n",
        "        \"\"\"Compute feedforward step\n",
        "        \"\"\"\n",
        "        A=[]\n",
        "        Z=[]\n",
        "\n",
        "        \n",
        "        A0 = self._add_bias_unit(X, how='column')\n",
        "        A0 = A0.T\n",
        "      \n",
        "        A.append(A0)\n",
        "        Z0 = W[0] @ A0\n",
        "        Z.append(Z0)\n",
        "        \n",
        "        A1 = self._phi(Z0)   #customized phi function only for the first layer\n",
        "        A1 = self._add_bias_unit(A1, how='row')\n",
        "        Z1 = W[1] @ A1\n",
        "        A.append(A1)\n",
        "        Z.append(Z1)\n",
        "        \n",
        "        for i in range(2,self.n_layer):\n",
        "          Ai = self._sigmoid(Z[-1])          \n",
        "          Ai = self._add_bias_unit(Ai, how='row')\n",
        "          Zi = W[i] @ Ai\n",
        "          A.append(Ai)\n",
        "          Z.append(Zi)\n",
        "\n",
        "        AOUT = self._sigmoid(Z[-1])\n",
        "        A.append(AOUT)\n",
        "       \n",
        "        return A, Z, AOUT\n",
        "    \n",
        "    def _get_gradient(self, A, Z, AOUT, Y_enc, W):\n",
        "        \"\"\" Compute gradient step using backpropagation.\n",
        "        \"\"\"\n",
        "        # vectorized backpropagation\n",
        "        V=[0]*self.n_layer\n",
        "        if self.costf == \"q\":\n",
        "          V[-1] = -2*(Y_enc-AOUT)*AOUT*(1-AOUT)  # last layer sensitivity\n",
        "        elif self.costf == \"c\":\n",
        "          V[-1] = (AOUT-Y_enc)\n",
        "          \n",
        "        #fill in all other sensitivities  \n",
        "        V[-2]=A[-2]*(1-A[-2])*(W[-1].T @ V[-1])\n",
        "        for i in range(self.n_layer-3,-1,-1):\n",
        "          V[i] = A[i+1]*(1-A[i+1])*(W[i+1].T @ V[i+1][1:,:])\n",
        "        \n",
        "        #first sensitivity will be different depending on phi function used\n",
        "        if self.phif == \"relu\":\n",
        "          Z_bias= self._add_bias_unit(Z[0], how='row')\n",
        "          if self.n_layer>2:\n",
        "            V[0] = (W[1].T @ V[1][1:,:])\n",
        "          else:\n",
        "            V[0]=(W[1].T @ V[1])\n",
        "          V[0][Z_bias<=0] = 0\n",
        "            \n",
        "            \n",
        "        elif self.phif == \"silu\":\n",
        "          if self.n_layer>2:\n",
        "            V[0] = (A[1]+(expit(self._add_bias_unit(Z[1], how='row'))*(1-A[1])))*(W[1].T @ V[1][1:,:])\n",
        "          #else:\n",
        "            #V[0] = (A[1]+(expit(self._add_bias_unit(Z[1], how='row'))*(1-A[1])))*(W[1].T @ V[1])\n",
        "          \n",
        "        elif self.phif == \"linear\":\n",
        "          if self.n_layer >2:\n",
        "            V[0]=(W[1].T @ V[1][1:,:])\n",
        "          else:\n",
        "            V[0]=(W[1].T @ V[1])\n",
        "          #if equals 2 then don't take off bias\n",
        "            \n",
        "\n",
        "        \n",
        "        grads = [0]*len(V)\n",
        "        grads[0] = V[0][1:,:] @ A[0].T\n",
        "        for i in range(1,len(V)-1):\n",
        "          grads[i] = V[i][1:,:] @ A[i].T\n",
        "        grads[-1] = V[-1] @ A[-2].T\n",
        "\n",
        "        for k in range(0,self.n_layer):\n",
        "          grads[k][:, 1:] += W[k][:, 1:] * self.l2_C \n",
        "        \n",
        "        return grads\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict class labels\"\"\"\n",
        "        _, _, AOUT = self._feedforward(X, self.W)\n",
        "        y_pred = np.argmax(AOUT, axis=0)\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QlYmb57SyCln",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MLPMiniBatch2(MultLayerPerceptronBase2):\n",
        "    def __init__(self, alpha=0.0, decrease_const=0.0, shuffle=True, \n",
        "                 minibatches=1, **kwds):        \n",
        "        # need to add to the original initializer \n",
        "        self.alpha = alpha\n",
        "        self.decrease_const = decrease_const\n",
        "        self.shuffle = shuffle\n",
        "        self.minibatches = minibatches\n",
        "        # but keep other keywords\n",
        "        super().__init__(**kwds)\n",
        "        \n",
        "    \n",
        "    def fit(self, X, y, print_progress=False):\n",
        "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
        "        X_data, y_data = X.copy(), y.copy()\n",
        "        Y_enc = self._encode_labels(y)\n",
        "        \n",
        "        # init weights and setup matrices\n",
        "        self.n_features_ = X_data.shape[1]\n",
        "        self.n_output_ = Y_enc.shape[0]\n",
        "        self.W = self._initialize_weights()\n",
        "\n",
        "        delta_W_prev=[]\n",
        "        for j in range(0,self.n_layer):\n",
        "          delta_Wj_prev = np.zeros(self.W[j].shape)\n",
        "          delta_W_prev.append(delta_Wj_prev)\n",
        "\n",
        "        self.cost_ = []\n",
        "        self.score_ = []\n",
        "        # get starting acc\n",
        "        self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
        "        for i in range(self.epochs):\n",
        "\n",
        "            # adaptive learning rate\n",
        "            self.eta /= (1 + self.decrease_const*i)\n",
        "\n",
        "            if print_progress>0 and (i+1)%print_progress==0:\n",
        "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
        "                sys.stderr.flush()\n",
        "\n",
        "            if self.shuffle:\n",
        "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
        "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
        "\n",
        "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
        "            mini_cost = []\n",
        "            for idx in mini:\n",
        "\n",
        "                # feedforward\n",
        "                A, Z, AOUT = self._feedforward(X_data[idx],\n",
        "                                         self.W)\n",
        "                \n",
        "                cost = self._cost(AOUT,Y_enc[:, idx],self.W) \n",
        "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
        "\n",
        "                # compute gradient via backpropagation\n",
        "                grads = self._get_gradient(A,Z,AOUT,\n",
        "                                          Y_enc=Y_enc[:, idx],\n",
        "                                          W=self.W)\n",
        "\n",
        "                # momentum calculations\n",
        "                delta_W=[]\n",
        "                for k in range(0,self.n_layer):\n",
        "                  delta_Wk = self.eta * grads[k]\n",
        "                  delta_W.append(delta_Wk)\n",
        "                  self.W[k] -= (delta_W[k] + (self.alpha * delta_W_prev[k]))\n",
        "                delta_W_prev = delta_W\n",
        "\n",
        "            self.cost_.append(mini_cost)\n",
        "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
        "            \n",
        "        return self\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gIb6S2w_yCxT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "params = dict(n_hidden=50, \n",
        "              C=0.1, # tradeoff L2 regularizer\n",
        "              epochs=200, # iterations\n",
        "              eta=0.001,  # learning rate\n",
        "              n_layer=5,\n",
        "              random_state=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ho8xM6PzMTu",
        "colab_type": "code",
        "outputId": "f85d7428-48f8-41a3-a436-56a480631750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#silu\n",
        "silu = MLPMiniBatch2(phif='silu', **params)\n",
        "silu.fit(X_train, y_train, print_progress=50)\n",
        "yhat = silu.predict(X_test)\n",
        "sorce_silu=confusion_matrix(y_test, yhat)\n",
        "sorce_silu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 200/200"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[60, 17,  0],\n",
              "       [38, 96,  4],\n",
              "       [ 2, 72,  2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "8Y7UFHhzHanH",
        "colab_type": "code",
        "outputId": "a8142a24-22e7-4952-a959-f502896ef9e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#relu\n",
        "relu = MLPMiniBatch2(phif='relu', **params)\n",
        "relu.fit(X_train, y_train, print_progress=50)\n",
        "yhat = relu.predict(X_test)\n",
        "sorce_relu=confusion_matrix(y_test, yhat)\n",
        "sorce_relu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 200/200"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,  77,   0],\n",
              "       [  0, 138,   0],\n",
              "       [  0,  76,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "wJoMJ-6rZ-QI",
        "colab_type": "code",
        "outputId": "dc7b71ba-2716-442c-9fbd-2362bed7bde1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#using cv to compare performance of relu and silu with the sigmoid and linear functions\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "skf = StratifiedKFold(n_splits=10, random_state=1)\n",
        "skf.get_n_splits(X, y)\n",
        "\n",
        "print(skf)  \n",
        "phi_1=MLPMiniBatch2(costf=\"q\", phif=\"sigmoid\", **params)\n",
        "phi_2=MLPMiniBatch2(costf=\"q\", phif=\"linear\", **params)\n",
        "phi_3=MLPMiniBatch2(costf=\"q\", phif=\"relu\", **params)\n",
        "phi_4=MLPMiniBatch2(costf=\"q\", phif=\"silu\", **params)\n",
        "\n",
        "phis = [phi_1, phi_2, phi_3, phi_4]\n",
        "phi_score_mat=[]\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train2, X_test2 = X[train_index], X[test_index]\n",
        "    y_train2, y_test2 = y[train_index], y[test_index]\n",
        "    #need to fit\n",
        "    phi_score=[]\n",
        "    for i in range(0,4):\n",
        "      \n",
        "      phis[i].fit(X_train2,y_train2)\n",
        "\n",
        "    #need to predict\n",
        "      yhat_i=phis[i].predict(X_test2)\n",
        "    #evaluate model  \n",
        "      phi_score_i=confusion_matrix(y_test2,yhat_i)\n",
        "      phi_cost_i=phi_score_i * cost_mat\n",
        "      phi_score.append(np.sum(phi_cost_i))\n",
        "    #keep track of the overall costs for each model per fold\n",
        "    phi_score_mat.append(phi_score)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StratifiedKFold(n_splits=10, random_state=1, shuffle=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Aszk4Rrmbxq7",
        "colab_type": "code",
        "outputId": "3a0a18c3-de68-4748-e7ec-f47eb0c412bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "#re-format the overall costs into a matrix\n",
        "phi_scores=np.zeros(shape=(10,4))\n",
        "for k in range(0,10):\n",
        "  for m in range(0,4):\n",
        "    phi_scores[k,m]=phi_score_mat[k][m]\n",
        "print(phi_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[32371. 32027. 38989. 33273.]\n",
            " [33592. 41280. 32756. 42246.]\n",
            " [43019. 32737. 33300. 33168.]\n",
            " [32912. 40673. 32948. 40676.]\n",
            " [33829. 38071. 37106. 36908.]\n",
            " [41674. 33681. 32951. 40306.]\n",
            " [33003. 40592. 38181. 35616.]\n",
            " [32610. 31192. 39293. 33045.]\n",
            " [31609. 38268. 39127. 33482.]\n",
            " [38309. 38417. 32570. 33037.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Mexs2aad5m0",
        "colab_type": "code",
        "outputId": "4ef6d9e9-8b5f-4c96-9738-279457b77283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "np.mean(phi_scores,0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([35292.8, 36693.8, 35722.1, 36175.7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "wvxcVxbQbZZ9",
        "colab_type": "code",
        "outputId": "7cb90a64-8300-4ba5-b9c4-1e4d0297c40b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "#visualize performance for different activation functions\n",
        "plt.boxplot(phi_scores)\n",
        "plt.xticks([1, 2, 3, 4], ['sigmoid', 'linear', 'relu','silu'])\n",
        "plt.title(\"Distribution of Cost vs. Phi Function\")\n",
        "plt.ylabel(\"Overall Cost\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFZCAYAAACSQfZwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7dcc502400>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "QSpiNs_Zipxv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The sigmoid activation function achieved the lowest mean misclassification cost in this test set, but it also has high variance. While the relu activation function has the second lowest mean misclassification cost, it has the least variance of all the models. When comparing the relu and silu functions, it appears using relu is slightly better because the variance is smaller. It is difficult to pick a best model here. Regardless, the misclassification costs for all are over the threshold to be useful for realtors, so we would not recommend any of these models for deployment. "
      ]
    }
  ]
}
